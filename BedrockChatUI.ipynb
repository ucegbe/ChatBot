{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce80d69-2321-49fc-b34c-bca443c76a2a",
   "metadata": {},
   "source": [
    "This notebook was tested in a `ml.t3.medium` instance and Sagemaker`Data Science 3` image Studio Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18167e24-3077-4e66-af16-d1bce1f4643e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"chatbot.png\" width=\"800\"/>\n",
    "\n",
    "This sample notebooks implements a general chatbot.\n",
    "Key functionalities include:\n",
    "1. Saving of Conversation History in DynamoDB\n",
    "2. Handling Document upload for various supported document format (PDF, JPG, CSV, EXCEL, PNG, TXT, JSON) by passing the document local or S3 path.\n",
    "3. Implementing various prompt template store locally (can also be stored in S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217fbc3-0e61-4cf6-b61a-b138e9dbec8f",
   "metadata": {},
   "source": [
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146a09e-407e-44da-98b0-39bf89599065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install boto3 -U langchain -U\n",
    "!pip install anthropic\n",
    "!pip install s3fs -U\n",
    "!pip install pandas -U\n",
    "!pip install --force-reinstall amazon-textract-textractor==1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ba6ed-5037-456f-89f9-5dd978b78ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from anthropic import Anthropic\n",
    "from botocore.config import Config\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.cell import Cell\n",
    "from openpyxl.worksheet.cell_range import CellRange\n",
    "import uuid\n",
    "from textractor import Textractor\n",
    "from textractor.visualizers.entitylist import EntityList\n",
    "from textractor.data.constants import TextractFeatures\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from textractor.data.text_linearization_config import TextLinearizationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59f0cb-7897-44ca-9754-80330c853e8e",
   "metadata": {},
   "source": [
    "#### Initialize Bedrock Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2cbfa50-c4a1-4fd3-8c68-4b205ba1d7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the bedrock runtime to invoke LLM\n",
    "config = Config(\n",
    "    read_timeout=600,\n",
    "    retries = dict(\n",
    "        max_attempts = 5 ## Handle retries\n",
    "    )\n",
    ")\n",
    "import boto3\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name='us-east-1',config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d49c0-58ae-4984-8c19-34c0e659e4cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create DynamoDB Table\n",
    "A DynamoDB Table is created with a user ID as partition Key and Session ID as sort key. \n",
    "This enables saving multiple chat session history under the same user id.\\\n",
    "Provide a bucket name that would be used to cache Amazon Textract results for document OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ad51c8-7eca-4482-a334-15c6358c8f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DYNAMODB_TABLE=\"SessionChatHistory\" \n",
    "DYNAMODB_USER= \"test-user\"\n",
    "SESSIONID=str(uuid.uuid4())\n",
    "DYNAMODB  = boto3.resource('dynamodb')\n",
    "dynamo=boto3.client('dynamodb')\n",
    "chat_hist=[]\n",
    "BUCKET=\"ENTER S3 BUCKET NAME\"\n",
    "S3=boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12996c34-511b-430b-8b73-e9ca8b838fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "try:\n",
    "    table = DYNAMODB.create_table(\n",
    "        TableName=DYNAMODB_TABLE,\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'UserId',  # Partition key\n",
    "                'KeyType': 'HASH'  \n",
    "            },\n",
    "            {\n",
    "                'AttributeName': 'SessionId',   # Sort key\n",
    "                'KeyType': 'RANGE'\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'UserId',\n",
    "                'AttributeType': 'S'   # String data type\n",
    "            },\n",
    "            {\n",
    "                'AttributeName': 'SessionId',\n",
    "                'AttributeType': 'S'\n",
    "            },\n",
    "        ],\n",
    "        BillingMode='PAY_PER_REQUEST'  # On-demand billing\n",
    "    )\n",
    "\n",
    "    print(\"Table status:\", table.table_status)\n",
    "\n",
    "    # Wait until the table exists.\n",
    "    table.meta.client.get_waiter(\"table_exists\").wait(TableName=\"SessionChatHistory\")\n",
    "    print(table.item_count)\n",
    "except dynamo.exceptions.ResourceInUseException as e:\n",
    "    print(e.response['Error']['Message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724ecf2-954f-4571-aa11-0b98558dffbc",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27929b3a-eae7-4abe-be72-f6932fb36184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strip_newline(cell):\n",
    "    \"\"\"\n",
    "    A utility function to strip newline characters from a cell.\n",
    "    Parameters:\n",
    "    cell (str): The cell value.\n",
    "    Returns:\n",
    "    str: The cell value with newline characters removed.\n",
    "    \"\"\"\n",
    "    return str(cell).strip()\n",
    "\n",
    "def table_parser_utills(file):    \n",
    "    \"\"\"\n",
    "    Converts an Excel table to a csv string, \n",
    "    handling duplicated values across merged cells.\n",
    "\n",
    "    Args:\n",
    "        file: Excel table  \n",
    "    Returns: \n",
    "        Pandas DataFrame representation of the Excel table\n",
    "    \"\"\"\n",
    "    # Read from S3 or local\n",
    "    if \"s3://\" in file:\n",
    "        s3 = boto3.client('s3')\n",
    "        match = re.match(\"s3://(.+?)/(.+)\", file)\n",
    "        if match:\n",
    "            bucket_name = match.group(1)\n",
    "            key = match.group(2)    \n",
    "            obj = s3.get_object(Bucket=bucket_name, Key=key)  \n",
    "        # Read Excel file from S3 into a buffer\n",
    "        xlsx_buffer = io.BytesIO(obj['Body'].read())\n",
    "        xlsx_buffer.seek(0) \n",
    "        # Load workbook, get active worksheet\n",
    "        wb = openpyxl.load_workbook(xlsx_buffer)\n",
    "        worksheet = wb.active\n",
    "    else:\n",
    "        # Load workbook, get active worksheet\n",
    "        wb = openpyxl.load_workbook(file)\n",
    "        worksheet = wb.active\n",
    "    # Unmerge cells, duplicate merged values to individual cells\n",
    "    all_merged_cell_ranges: list[CellRange] = list(\n",
    "            worksheet.merged_cells.ranges\n",
    "        )\n",
    "    for merged_cell_range in all_merged_cell_ranges:\n",
    "        merged_cell: Cell = merged_cell_range.start_cell\n",
    "        worksheet.unmerge_cells(range_string=merged_cell_range.coord)\n",
    "        for row_index, col_index in merged_cell_range.cells:\n",
    "            cell: Cell = worksheet.cell(row=row_index, column=col_index)\n",
    "            cell.value = merged_cell.value\n",
    "    # determine table header index\n",
    "    df = pd.DataFrame(worksheet.values)\n",
    "    df=df.map(strip_newline)  \n",
    "    return df.to_csv(sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b52d892-c56e-4c33-af8f-94df9ba4df48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_s3_keys(prefix):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_objects_v2(Bucket=BUCKET, Prefix=prefix)\n",
    "    keys=\"\"\n",
    "    if \"Contents\" in response:\n",
    "        keys = []\n",
    "        for obj in response['Contents']:\n",
    "            key = obj['Key']\n",
    "            name = key[len(prefix):]\n",
    "            keys.append(name)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a65ff2ff-c800-40c4-812b-60112b847e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exract_pdf_text_aws(file):\n",
    "    \"\"\"\n",
    "    Extract text from PDF/image files using Amazon Textract service.\n",
    "    Supports PDFs/Images stored locally or in S3.\n",
    "    \n",
    "    Parameters:\n",
    "        file (str): Path or S3 URI of PDF file\n",
    "\n",
    "    Returns:\n",
    "        text (str): Extracted text from PDF\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    file_base_name=os.path.basename(file)\n",
    "    # Checking if extracted doc content is in S3\n",
    "    if [x for x in get_s3_keys(\"extracted_output/\") if file_base_name in x]:      \n",
    "        response = S3.get_object(Bucket=BUCKET, Key=f\"extracted_output/{file_base_name}.txt\")\n",
    "        text = response['Body'].read()\n",
    "        return text\n",
    "    else:\n",
    "        dir_name, ext = os.path.splitext(file)\n",
    "        extractor = Textractor(region_name=\"us-east-1\")\n",
    "        # Asynchronous call, you will experience some wait time. Try caching results for better experience\n",
    "        if \"s3://\" in file and \"pdf\" in ext:\n",
    "            print(\"Asynchronous call, you may experience some wait time.\")\n",
    "            document = extractor.start_document_analysis(\n",
    "            file_source=file,\n",
    "            features=[TextractFeatures.LAYOUT,TextractFeatures.TABLES],       \n",
    "            save_image=False,   \n",
    "            s3_output_path=f\"s3://{BUCKET}/textract_output/\"\n",
    "        )\n",
    "        # Asynchronous call, you will experience some wait time. Try caching results for better experience\n",
    "        elif \"s3://\" not in file and \"pdf\" in ext:\n",
    "            print(\"Asynchronous call, you may experience some wait time.\")\n",
    "            document = extractor.start_document_analysis(\n",
    "            file_source=file,\n",
    "            features=[TextractFeatures.LAYOUT,TextractFeatures.TABLES],\n",
    "            save_image=False,  \n",
    "            s3_upload_path=f\"s3://{BUCKET}\",\n",
    "            s3_output_path=f\"s3://{BUCKET}/textract_output/\"\n",
    "        )\n",
    "        #Synchronous call\n",
    "        else:\n",
    "            document = extractor.analyze_document(\n",
    "            file_source=file,\n",
    "            features=[TextractFeatures.LAYOUT,TextractFeatures.TABLES],  \n",
    "            save_image=False,\n",
    "        )\n",
    "\n",
    "        config = TextLinearizationConfig(\n",
    "        hide_figure_layout=True,   \n",
    "        hide_header_layout=False,    \n",
    "        table_prefix=\"<table>\",\n",
    "        table_suffix=\"</table>\",\n",
    "        )\n",
    "        # Upload extracted content to s3\n",
    "        S3.put_object(Body=document.get_text(config=config), Bucket=BUCKET, Key=f\"extracted_output/{file_base_name}.txt\") \n",
    "        return document.get_text(config=config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c1c2ca3-0874-4da2-94d9-3c02daeeb233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_doc_upload_or_s3(file):\n",
    "    \"\"\"\n",
    "    Handle parsing of documents from local file system or S3.\n",
    "\n",
    "    Supports PDF, PNG, JPG, CSV, XLSX, JSON and Text files.\n",
    "\n",
    "    Parameters:\n",
    "        file (str): Path or S3 URI of document to parse\n",
    "\n",
    "    Returns:\n",
    "        content: Parsed contents of the file in appropriate format\n",
    "    \"\"\"\n",
    "    dir_name, ext = os.path.splitext(file)\n",
    "    if  ext in [\".pdf\", \".png\", \".jpg\"]:   \n",
    "        content=exract_pdf_text_aws(file)\n",
    "    elif \"csv\"  in ext:\n",
    "        content= pd.read_csv(file)\n",
    "    elif ext in [\".xlsx\", \".xlx\"]:\n",
    "        content=table_parser_utills(file)\n",
    "    elif \"json\" in ext and \"s3://\" not in dir_name:\n",
    "        with open(file) as json_file:       \n",
    "            content = json.load(json_file)\n",
    "    elif  \"json\" in ext and \"s3://\" in dir_name:\n",
    "        s3 = boto3.client('s3')\n",
    "        match = re.match(\"s3://(.+?)/(.+)\", file)\n",
    "        if match:\n",
    "            bucket_name = match.group(1)\n",
    "            key = match.group(2)    \n",
    "            obj = s3.get_object(Bucket=bucket_name, Key=key)        \n",
    "            content = json.loads(obj['Body'].read())\n",
    "    elif \"txt\" in ext and \"s3://\" not in dir_name:\n",
    "        with open(file, \"r\") as txt_file:       \n",
    "            content = txt_file.read()\n",
    "    elif  \"txt\" in ext and \"s3://\" in dir_name:\n",
    "        s3 = boto3.client('s3')\n",
    "        match = re.match(\"s3://(.+?)/(.+)\", file)\n",
    "        if match:\n",
    "            bucket_name = match.group(1)\n",
    "            key = match.group(2)    \n",
    "            obj = s3.get_object(Bucket=bucket_name, Key=key)        \n",
    "            content = obj['Body'].read()\n",
    "    # Implement any of file extension logic \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc7fdc72-92da-4158-8cbe-b8220a8cd431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def put_db(messages):\n",
    "    \"\"\"Store long term chat history in DynamoDB\"\"\"    \n",
    "    chat_item = {\n",
    "        \"UserId\": DYNAMODB_USER, # user id\n",
    "        \"SessionId\": SESSIONID, # User session id\n",
    "        \"messages\": [messages]  # 'messages' is a list of dictionaries\n",
    "    }\n",
    "    existing_item = DYNAMODB.Table(DYNAMODB_TABLE).get_item(Key={\"UserId\": DYNAMODB_USER, \"SessionId\":SESSIONID})\n",
    "    if \"Item\" in existing_item:\n",
    "        existing_messages = existing_item[\"Item\"][\"messages\"]\n",
    "        chat_item[\"messages\"] = existing_messages + [messages]\n",
    "\n",
    "    response = DYNAMODB.Table(DYNAMODB_TABLE).put_item(\n",
    "        Item=chat_item\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1444e-a734-4a80-bce2-f51730af9517",
   "metadata": {},
   "source": [
    "#### Chat Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7ea26-8cb1-471c-867a-fb028125d094",
   "metadata": {},
   "source": [
    "This function calls the Anthropic Claude Bedrock api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49c188da-5167-4495-b951-f95ea40a59d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conversation_bedroc_chat_(question, upload_doc=None):\n",
    "    \"\"\"\n",
    "    Function takes a user query and a document path (from S3 or Local)\n",
    "    passing a document path is optional\n",
    "    \"\"\"\n",
    "    current_chat=\"\"\n",
    "    # Retrieve past chat history from Dynamodb\n",
    "    if DYNAMODB_TABLE:\n",
    "        chat_histories = DYNAMODB.Table(DYNAMODB_TABLE).get_item(Key={\"UserId\": DYNAMODB_USER, \"SessionId\":SESSIONID})\n",
    "        if \"Item\" in chat_histories:\n",
    "            chat_hist=chat_histories['Item']['messages']\n",
    "            # Returning the latest 10 conversation turns\n",
    "            for chat in chat_histories['Item']['messages'][-10:]:\n",
    "                for k, v in chat.items():\n",
    "                    current_chat+=v\n",
    "        else:\n",
    "            chat_hist=[]\n",
    "    else:\n",
    "        for chat in chat_hist:\n",
    "            for k, v in chat.items():\n",
    "                current_chat+=v\n",
    "    ## prompt template for when a user uploads a doc\n",
    "    if upload_doc:\n",
    "        doc=handle_doc_upload_or_s3(upload_doc)\n",
    "        with open(\"prompt/doc_chat.txt\",\"r\") as f:\n",
    "            chat_template=f.read()\n",
    "        values = {\n",
    "        \"doc\": doc,\n",
    "        \"prompt\": question,\n",
    "        \"current_chat\": current_chat,\n",
    "        }\n",
    "        prompt=f\"\\n\\nHuman: {chat_template.format(**values)}\\n\\nAssistant:\"    \n",
    "    else:        \n",
    "        # Chat template for open ended query\n",
    "        with open(\"prompt/chat.txt\",\"r\") as f:\n",
    "            chat_template=f.read()\n",
    "        values = {\n",
    "        \"prompt\": question,\n",
    "        \"current_chat\": current_chat,\n",
    "        }\n",
    "        prompt=f\"\\n\\nHuman: {chat_template.format(**values)}\\n\\nAssistant:\"\n",
    "\n",
    "    inference_modifier = {'max_tokens_to_sample':1500, \n",
    "                          \"temperature\":0.5,\n",
    "                          # \"top_k\":250,\n",
    "                          # \"top_p\":1,    \n",
    "                          \"stop_sequences\": [\"Human:\"]\n",
    "                         }\n",
    "    llm = Bedrock(model_id='anthropic.claude-v2',  # Change to a different claude model id\n",
    "                  client=bedrock_runtime, model_kwargs = inference_modifier,\n",
    "                  streaming=True,  # Toggle this to turn streaming on or off\n",
    "                  callbacks=[StreamingStdOutCallbackHandler() ])\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    chat_history={\"user\": f\"{question}\",\n",
    "    \"assiatant\":f\"\\n\\nAssistant: {response}\\n\\nHuman: \"} \n",
    "    #store conversation memory in DynamoDB table\n",
    "    if DYNAMODB_TABLE:\n",
    "        put_db(chat_history)\n",
    "    # use local memory for storage\n",
    "    else:\n",
    "        chat_hist.append(chat_history)   \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e31287-db05-4e8a-86bc-c46ce91da664",
   "metadata": {},
   "source": [
    "#### Query the the chat bot with your questions.\n",
    "Also takes a document path stored in s3 or local. Once a document path is passed, a different prompt template is triggered.\n",
    "However, chat history (question and response only) are store in the DynamoDB table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1e2f81b-4c73-4de1-b4c8-2c051914e3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello there! I'm happy to converse with you and provide helpful information to the best of my abilities. As an AI assistant created by Anthropic to be helpful, harmless, and honest, I will do my best to give high quality responses in a friendly markdown format. Please feel free to ask me anything!"
     ]
    }
   ],
   "source": [
    "question=\"Hello\"\n",
    "res=conversation_bedroc_chat_(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97752f-c43d-41f5-85fd-03c940a54fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
